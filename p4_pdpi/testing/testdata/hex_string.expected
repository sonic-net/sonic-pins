$ BitsetToHexString(std::bitset<1>("0"))
-> 0x0

$ BitsetToHexString(std::bitset<1>("1"))
-> 0x1

$ BitsetToHexString(std::bitset<3>("100"))
-> 0x4

$ BitsetToHexString(std::bitset<3>("101"))
-> 0x5

$ BitsetToHexString(std::bitset<3>("110"))
-> 0x6

$ BitsetToHexString(std::bitset<3>("111"))
-> 0x7

$ BitsetToHexString(std::bitset<4>("1110"))
-> 0xe

$ BitsetToHexString(std::bitset<4>("1111"))
-> 0xf

$ BitsetToHexString(std::bitset<5>("00000"))
-> 0x00

$ BitsetToHexString(std::bitset<5>("00001"))
-> 0x01

$ BitsetToHexString(std::bitset<5>("10000"))
-> 0x10

$ BitsetToHexString(std::bitset<5>("10001"))
-> 0x11

$ BitsetToHexString(std::bitset<5>("11111"))
-> 0x1f

$ BitsetToHexString<8 * sizeof(int)>(0)
-> 0x00000000

$ BitsetToHexString<8 * sizeof(int)>(1)
-> 0x00000001

$ BitsetToHexString<8 * sizeof(int)>(-1)
-> 0xffffffff

$ BitsetToHexString<8 * sizeof(int)>(15)
-> 0x0000000f

$ BitsetToHexString<8 * sizeof(int)>(std::numeric_limits<int>::max())
-> 0x7fffffff

$ BitsetToHexString<8 * sizeof(int)>(std::numeric_limits<int>::min())
-> 0x80000000

$ HexStringToBitset<1>("0x0")
-> 0

$ HexStringToBitset<1>("0x1")
-> 1

$ HexStringToBitset<1>("0x01")
-> error: INVALID_ARGUMENT: illegal conversion from hex string '0x01' to 1 bits; expected 1 hex digits but got 2

$ HexStringToBitset<1>("0x000")
-> error: INVALID_ARGUMENT: illegal conversion from hex string '0x000' to 1 bits; expected 1 hex digits but got 3

$ HexStringToBitset<1>("0x2")
-> error: INVALID_ARGUMENT: hex string '0x2' has bit #2 set to 1; conversion to 1 bits would lose information

$ HexStringToBitset<7>("0xf0")
-> error: INVALID_ARGUMENT: hex string '0xf0' has bit #8 set to 1; conversion to 7 bits would lose information

$ HexStringToBitset<8>("0xf0")
-> 11110000

$ HexStringToBitset<8>("0x00ff")
-> error: INVALID_ARGUMENT: illegal conversion from hex string '0x00ff' to 8 bits; expected 2 hex digits but got 4

$ HexStringToInt("0x0")
-> 0

$ HexStringToInt("0x1")
-> 1

$ HexStringToInt("0x01")
-> 1

$ HexStringToInt("0x000")
-> 0

$ HexStringToInt("0x0fffffff")
-> 268435455

$ HexStringToInt("0xffffffff")
-> -1

$ HexStringToInt("0x100000000")
-> error: INVALID_ARGUMENT: hex string '0x100000000' has bit #33 set to 1; conversion to 32 bits would lose information

$ HexStringToInt32( BitsetToHexString<32>(std::numeric_limits<int32_t>::max()))
-> 2147483647

$ HexStringToInt32( BitsetToHexString<64>(std::numeric_limits<int64_t>::max()))
-> error: INVALID_ARGUMENT: hex string '0x7fffffffffffffff' has bit #33 set to 1; conversion to 32 bits would lose information

$ HexStringToInt32( BitsetToHexString<32>(std::numeric_limits<int32_t>::min()))
-> -2147483648

$ HexStringToInt32( BitsetToHexString<64>(std::numeric_limits<int64_t>::min()))
-> error: INVALID_ARGUMENT: hex string '0x8000000000000000' has bit #64 set to 1; conversion to 32 bits would lose information

$ HexStringToInt64( BitsetToHexString<32>(std::numeric_limits<int32_t>::max()))
-> 2147483647

$ HexStringToInt64( BitsetToHexString<64>(std::numeric_limits<int64_t>::max()))
-> 9223372036854775807

$ HexStringToInt64( BitsetToHexString<32>(std::numeric_limits<int32_t>::min()))
-> 2147483648

$ HexStringToInt64( BitsetToHexString<64>(std::numeric_limits<int64_t>::min()))
-> -9223372036854775808

$ HexStringToUint32("0x0000000000000000000000000001")
-> 1

$ HexStringToUint32("0xffffffff")
-> 4294967295

$ HexStringToUint32("0x0ffffffff")
-> 4294967295

$ HexStringToUint32("0x1ffffffff")
-> error: INVALID_ARGUMENT: hex string '0x1ffffffff' has bit #33 set to 1; conversion to 32 bits would lose information

$ HexStringToUint64("0xffffffffffffffff")
-> 18446744073709551615

$ HexStringToUint64("0x0ffffffffffffffff")
-> 18446744073709551615

$ HexStringToUint64("0x1ffffffffffffffff")
-> error: INVALID_ARGUMENT: hex string '0x1ffffffffffffffff' has bit #65 set to 1; conversion to 64 bits would lose information
